{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RNN.ipynb","provenance":[],"collapsed_sections":["6h1HF0TGSQ5b"],"authorship_tag":"ABX9TyNWh77rqMYyNj2dvi3tx+zv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6h1HF0TGSQ5b"},"source":["# Importing the Required Modules"]},{"cell_type":"markdown","metadata":{"id":"vxuvYa_rO3YZ"},"source":["You'll need to pip install the following libraries:"]},{"cell_type":"code","metadata":{"id":"OirSMiXkSTnd"},"source":["!pip install swifter\n","!pip install rouge\n","!pip install clean-text\n","!pip install Unidecode\n","!pip install torch\n","!pip install transformers\n","# !pip install datasets \n","!pip install tensorflow\n","!pip install keras"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ItPbTQritvWr"},"source":["Once that's done, let's import all the modules we'll be using:"]},{"cell_type":"code","metadata":{"id":"feYg6jl-SVGi"},"source":["# Standard Libraries\n","import re\n","import pickle\n","\n","# Data Libraries\n","import pandas as pd\n","import numpy as np\n","import swifter\n","\n","# Data Preprocessing\n","import nltk\n","from nltk.util import ngrams\n","from cleantext import clean\n","\n","# Metrics\n","from rouge import Rouge \n","\n","# Data Visualisation\n","import matplotlib.pyplot as plt\n","from IPython.core.display import display, HTML\n","\n","# Functionality\n","from typing import List, Dict, Union"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras import layers \n","from keras.layers import Dropout, Dense,Input,Embedding,Flatten, MaxPooling1D, Conv1D\n","from keras.models import Sequential,Model\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import numpy as np\n","from sklearn import metrics\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.datasets import fetch_20newsgroups\n","from keras.layers.merge import Concatenate\n","from sklearn.metrics import classification_report \n","from sklearn.metrics import confusion_matrix\n","from keras.utils.np_utils import to_categorical"],"metadata":{"id":"e-ANCrB6aUB7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"adO1g4ujaLWD"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","source":["# Loading datasets"],"metadata":{"id":"hPLaAagveRAh"}},{"cell_type":"code","source":["data_news_all = pd.read_csv(f\"{PATH}/Research/Combined/sarcastic_nonsarcastic_news_processed-19702-20746.csv\")  #35%"],"metadata":{"id":"QA7TGSTENGC7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_news_all = pd.read_csv(f\"{PATH}/Research/Combined/sarcasm_dataset_1000_1000_1000.csv\", delimiter='\\t') \n","article = data_news_all['text'].values\n","label = data_news_all['sarcastic'].values"],"metadata":{"id":"Ol0QyvF9VgYj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_news_all.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sAgPzwaiVgK3","executionInfo":{"status":"ok","timestamp":1644810502402,"user_tz":-60,"elapsed":183,"user":{"displayName":"Andreea Iuga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05848952328031788406"}},"outputId":"8008d06d-f9de-4026-deaf-3dcbda4c439b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 28447 entries, 0 to 28446\n","Data columns (total 6 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   id          28447 non-null  object\n"," 1   sarcastic   28447 non-null  object\n"," 2   topic       28447 non-null  object\n"," 3   url         28447 non-null  object\n"," 4   image_path  28447 non-null  object\n"," 5   text        28447 non-null  object\n","dtypes: object(6)\n","memory usage: 1.3+ MB\n"]}]},{"cell_type":"code","source":["article = data_news_all['article_processed'].values\n","label = data_news_all['sarcastic'].values"],"metadata":{"id":"XtlZXOPpASmZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["article_train, article_rem, label_train, label_rem = train_test_split(article, label, train_size=0.8, random_state=42) \n","article_valid, article_test, label_valid, label_test = train_test_split(article_rem, label_rem, test_size=0.5, random_state=42) "],"metadata":{"id":"4qhpEtmLhHmO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Shape of training data: ')\n","print(article_train.shape)\n","print(label_train.shape)\n","\n","print('Shape of val data: ')\n","print(article_valid.shape)\n","print(label_valid.shape)\n","\n","print('Shape of test data: ')\n","print(article_test.shape)\n","print(label_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BxypRyX-WT5H","executionInfo":{"status":"ok","timestamp":1644886555986,"user_tz":-60,"elapsed":6,"user":{"displayName":"Andreea Iuga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05848952328031788406"}},"outputId":"76c47d3f-3205-43cb-c1ec-0bbdb6b03fac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of training data: \n","(32312,)\n","(32312,)\n","Shape of val data: \n","(4039,)\n","(4039,)\n","Shape of test data: \n","(4040,)\n","(4040,)\n"]}]},{"cell_type":"markdown","source":["## RNN  "],"metadata":{"id":"iHceEiFe1pdI"}},{"cell_type":"code","source":["from keras.layers import Dropout, Dense, GRU, Embedding\n","from keras.models import Sequential\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import numpy as np\n","from sklearn import metrics\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import model_from_json"],"metadata":{"id":"LwwLSl2t5-E6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["article = data_news_all['article_processed'].values\n","label = data_news_all['sarcastic'].values"],"metadata":{"id":"31fl9taWAn2O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["article_train, article_rem, label_train, label_rem = train_test_split(article, label, train_size=0.8, random_state=42) \n","article_valid, article_test, label_valid, label_test = train_test_split(article_rem, label_rem, test_size=0.5, random_state=42) "],"metadata":{"id":"nPpC1wtDAo5f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Shape of training data: ')\n","print(article_train.shape)\n","print(label_train.shape)\n","\n","print('Shape of val data: ')\n","print(article_valid.shape)\n","print(label_valid.shape)\n","\n","print('Shape of test data: ')\n","print(article_test.shape)\n","print(label_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AoI-ZKvwArcH","executionInfo":{"status":"ok","timestamp":1643731679553,"user_tz":-60,"elapsed":2,"user":{"displayName":"Andreea Iuga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05848952328031788406"}},"outputId":"26447cac-11bb-4add-d286-9ee73973f41a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of training data: \n","(32312,)\n","(32312,)\n","Shape of val data: \n","(4039,)\n","(4039,)\n","Shape of test data: \n","(4040,)\n","(4040,)\n"]}]},{"cell_type":"markdown","source":["### CREATE MODEL"],"metadata":{"id":"vRkRLWIPBH40"}},{"cell_type":"code","source":["def loadData_Tokenizer(X_train, X_test, MAX_NUM_WORDS=75000, MAX_SEQUENCE_LENGTH=500):\n","\n","  np.random.seed(7)\n","  text = np.concatenate((X_train, X_test), axis=0)\n","  text = np.array(text)\n","\n","  tokenizer = Tokenizer(num_words=MAX_NUM_WORDS) #keeps the most frequent words \n","  tokenizer.fit_on_texts(text)\n","  sequences = tokenizer.texts_to_sequences(text)\n","  # Xcnn_train = tokenizer.texts_to_sequences(X_train)\n","  # Xcnn_test = tokenizer.texts_to_sequences(X_test)\n","\n","  word_index = tokenizer.word_index\n","  vocab_size = len(tokenizer.word_index) + 1  \n","\n","  text = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","  # Xcnn_train = pad_sequences(Xcnn_train, maxlen=MAX_SEQUENCE_LENGTH)\n","  # Xcnn_test = pad_sequences(Xcnn_test, maxlen=MAX_SEQUENCE_LENGTH) \n","  print('Found %s unique tokens.' % len(word_index))\n","\n","  indices = np.arange(text.shape[0])\n","  # np.random.shuffle(indices)\n","  text = text[indices]\n","  print(text.shape)\n","  X_train = text[0:len(X_train), ]\n","  X_test = text[len(X_train):, ]\n","\n","  embeddings_index = {}\n","  # f = open(f\"{PATH}/Research/corola.300.20.vec\", encoding=\"utf8\")\n","  f = open(f\"{PATH}/Research/Embeddings/corola.300.20.vec\")\n","  for line in f:\n","      values = line.split()\n","      word = values[0]\n","      try:\n","          coefs = np.asarray(values[1:], dtype='float32')\n","      except:\n","          pass\n","      embeddings_index[word] = coefs\n","  f.close()\n","\n","  return X_train, X_test, word_index, embeddings_index"],"metadata":{"id":"FdvK0SXx1ozE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def Build_Model_RNN_Text(word_index, embeddings_index, nclasses,  MAX_SEQUENCE_LENGTH=500, EMBEDDING_DIM=300, dropout=0.5):\n","    \"\"\"\n","    def buildModel_RNN(word_index, embeddings_index, nclasses,  MAX_SEQUENCE_LENGTH=500, EMBEDDING_DIM=50, dropout=0.5):\n","    word_index in word index ,\n","    embeddings_index is embeddings index, look at data_helper.py\n","    nClasses is number of classes,\n","    MAX_SEQUENCE_LENGTH is maximum lenght of text sequences\n","    \"\"\"\n","\n","    model = Sequential()\n","    hidden_layer = 3\n","    gru_node = 32\n","\n","    embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n","    for word, i in word_index.items():\n","        embedding_vector = embeddings_index.get(word)\n","        if embedding_vector is not None:\n","            # words not found in embedding index will be all-zeros.\n","            if len(embedding_matrix[i]) != len(embedding_vector):\n","                print(\"could not broadcast input array from shape\", str(len(embedding_matrix[i])),\n","                      \"into shape\", str(len(embedding_vector)), \" Please make sure your\"\n","                                                                \" EMBEDDING_DIM is equal to embedding_vector file ,GloVe,\")\n","                exit(1)\n","            embedding_matrix[i] = embedding_vector\n","    model.add(Embedding(len(word_index) + 1,\n","                                EMBEDDING_DIM,\n","                                weights=[embedding_matrix],\n","                                input_length=MAX_SEQUENCE_LENGTH,\n","                                trainable=True))\n","\n","\n","    print(gru_node)\n","    for i in range(0,hidden_layer):\n","        model.add(GRU(gru_node,return_sequences=True, recurrent_dropout=0.2))\n","        model.add(Dropout(dropout))\n","    model.add(GRU(gru_node, recurrent_dropout=0.2))\n","    model.add(Dropout(dropout))\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dense(nclasses, activation='softmax'))\n","\n","\n","    model.compile(loss='sparse_categorical_crossentropy',\n","                      optimizer='adam',\n","                      metrics=['accuracy'])\n","    return model"],"metadata":{"id":"HLSmQSMP1ovM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# article_train, article_test, label_train, label_test = train_test_split(article, label, test_size=0.25, random_state=42) "],"metadata":{"id":"u1619pSM1ork"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train = article_train\n","X_test = article_test\n","y_train = label_train\n","y_test = label_test\n","\n","X_train,X_test, word_index,embeddings_index = loadData_Tokenizer(X_train,X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yr4FdYEx89pC","executionInfo":{"status":"ok","timestamp":1643579690163,"user_tz":-60,"elapsed":36430,"user":{"displayName":"Andreea Iuga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05848952328031788406"}},"outputId":"7b771acc-b437-448a-df72-afab8dbdd6f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 163493 unique tokens.\n","(36352, 500)\n"]}]},{"cell_type":"code","source":["model_RNN = Build_Model_RNN_Text(word_index,embeddings_index, 20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NCLxeBjM83WV","executionInfo":{"status":"ok","timestamp":1644810963717,"user_tz":-60,"elapsed":1417,"user":{"displayName":"Andreea Iuga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05848952328031788406"}},"outputId":"603f4f62-96bb-443d-adff-110b3b6bcc2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["32\n","WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]}]},{"cell_type":"code","source":["model_RNN.fit(X_train, y_train,\n","                              validation_data=(X_test, y_test),\n","                              epochs=2,\n","                              batch_size=128,\n","                              verbose=0)"],"metadata":{"id":"aCjFXN4y83QN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted = model_RNN.predict(X_test)"],"metadata":{"id":"sQJMsZgy83B1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted = np.argmax(predicted, axis=1)\n","\n","print(metrics.classification_report(y_test, predicted))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"17z1Yt_c82-_","executionInfo":{"status":"ok","timestamp":1643492568115,"user_tz":-60,"elapsed":12,"user":{"displayName":"Andreea Iuga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05848952328031788406"}},"outputId":"c1d6cdc7-4896-4ebc-a60f-cdcd660b55a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.99      0.99      0.99      6029\n","           1       0.99      0.98      0.99      4933\n","\n","    accuracy                           0.99     10962\n","   macro avg       0.99      0.99      0.99     10962\n","weighted avg       0.99      0.99      0.99     10962\n","\n"]}]},{"cell_type":"code","source":["scores = model_RNN.evaluate(X_test, y_test, verbose=0)\n","print(\"%s: %.2f%%\" % (model_RNN.metrics_names[1], scores[1]*100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6XlcmllO827e","executionInfo":{"status":"ok","timestamp":1643494229565,"user_tz":-60,"elapsed":93210,"user":{"displayName":"Andreea Iuga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05848952328031788406"}},"outputId":"c293e6ad-4aa6-493a-ab64-b6f8c009426c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy: 98.77%\n"]}]},{"cell_type":"code","source":["print(\"%s: %.2f%%\" % (model_RNN.metrics_names[0], scores[1]*100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kcxR9Tz70R6a","executionInfo":{"status":"ok","timestamp":1643494242962,"user_tz":-60,"elapsed":255,"user":{"displayName":"Andreea Iuga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05848952328031788406"}},"outputId":"d6dd6444-1c1d-4107-893e-cde694b9cf0b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loss: 98.77%\n"]}]},{"cell_type":"markdown","source":["https://machinelearningmastery.com/save-load-keras-deep-learning-models/"],"metadata":{"id":"C_N4WmIkN-FK"}},{"cell_type":"code","source":["# serialize model to JSON\n","model_json = model_CNN.to_json()\n","with open(f\"{PATH}/Research/RNN/model_RNN.json\", \"w\") as json_file:\n","    json_file.write(model_json)\n","# serialize weights to HDF5\n","model_CNN.save_weights(f\"{PATH}/Research/RNN/model_RNN.h5\")\n","print(\"Saved model to disk\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"18beEAb6Nj6l","executionInfo":{"status":"ok","timestamp":1643492983031,"user_tz":-60,"elapsed":4930,"user":{"displayName":"Andreea Iuga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05848952328031788406"}},"outputId":"6a1d0b37-b989-443a-b83e-e2a5594aae55"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved model to disk\n"]}]},{"cell_type":"markdown","source":["### LOAD MODEL"],"metadata":{"id":"Xr5Gzq6LBLFl"}},{"cell_type":"code","source":["def loadData_Tokenizer(X_train, X_valid, X_test, MAX_NUM_WORDS=75000, MAX_SEQUENCE_LENGTH=1000):\n","\n","  # np.random.seed(7)\n","\n","  # tokenizer = Tokenizer(num_words=MAX_NUM_WORDS) #keeps the most frequent words \n","  # tokenizer.fit_on_texts(X_train)\n","  # sequences = tokenizer.texts_to_sequences(X_train)\n","\n","  # word_index = tokenizer.word_index\n","  # vocab_size = len(tokenizer.word_index) + 1  \n","\n","  # X_train = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","  # # Xcnn_train = pad_sequences(Xcnn_train, maxlen=MAX_SEQUENCE_LENGTH)\n","  # # Xcnn_test = pad_sequences(Xcnn_test, maxlen=MAX_SEQUENCE_LENGTH) \n","  # print('Found %s unique tokens.' % len(word_index))\n","\n","  # X_test_sequences = tokenizer.texts_to_sequences(X_test)\n","  # X_test = pad_sequences(X_test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","\n","  # X_valid_sequences = tokenizer.texts_to_sequences(X_valid)\n","  # X_valid = pad_sequences(X_valid_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","  # # indices = np.arange(text.shape[0])\n","  # # # np.random.shuffle(indices)\n","  # # text = text[indices]\n","  # # print(text.shape)\n","  # # X_train = text[0:len(X_train), ]\n","  # # X_test = text[len(X_train):, ]\n","\n","  np.random.seed(7)\n","  text = np.concatenate((X_train, X_valid, X_test), axis=0)\n","  text = np.array(text)\n","\n","  tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n","  tokenizer.fit_on_texts(text)\n","\n","  sequences = tokenizer.texts_to_sequences(text)\n","  word_index = tokenizer.word_index\n","  text = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","  print('Found %s unique tokens.' % len(word_index))\n","\n","  indices = np.arange(text.shape[0])\n","  # np.random.shuffle(indices)\n","  text = text[indices]\n","  print(text.shape)\n","\n","  X_train = text[0:len(X_train), ]\n","  X_valid = text[len(X_train):(len(X_train)+len(X_valid)), ]\n","  X_test = text[(len(X_train)+len(X_valid)):, ]\n","  embeddings_index = {}\n","  # f = open(f\"{PATH}/Research/corola.300.20.vec\", encoding=\"utf8\")\n","  f = open(f\"{PATH}/Research/Embeddings/corola.300.20.vec\")\n","  for line in f:\n","      values = line.split()\n","      word = values[0]\n","      try:\n","          coefs = np.asarray(values[1:], dtype='float32')\n","      except:\n","          pass\n","      embeddings_index[word] = coefs\n","  f.close()\n","\n","  return X_train, X_valid, X_test, word_index, embeddings_index"],"metadata":{"id":"n2B6qIMeCaAE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load json and create model\n","json_file = open(f\"{PATH}/Research/RNN-LSTM/model_RNN-LSTM-2.json\", 'r')\n","loaded_model_json = json_file.read()\n","json_file.close()\n","loaded_model = model_from_json(loaded_model_json)\n","# load weights into new model\n","loaded_model.load_weights(f\"{PATH}/Research/RNN-LSTM/model_RNN-LSTM-2.h5\")\n","print(\"Loaded model from disk\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VhIaG28kBMZO","executionInfo":{"status":"ok","timestamp":1643731734157,"user_tz":-60,"elapsed":1455,"user":{"displayName":"Andreea Iuga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05848952328031788406"}},"outputId":"36d191ff-dc62-4b7d-b7e5-0b9ccbb4806d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded model from disk\n"]}]},{"cell_type":"code","source":["loaded_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"metadata":{"id":"Wbs5S_6UBtPD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train = article_train\n","X_test = article_test\n","y_train = label_train\n","y_test = label_test\n","X_valid = article_valid\n","y_valid = label_valid\n","X_train, X_valid, X_test, word_index,embeddings_index = loadData_Tokenizer(X_train,X_valid,X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gbYiRi_MCTzO","executionInfo":{"status":"ok","timestamp":1643731729995,"user_tz":-60,"elapsed":47369,"user":{"displayName":"Andreea Iuga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05848952328031788406"}},"outputId":"a143e867-3910-4e93-86ce-48fb3ef8a5b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 171595 unique tokens.\n","(40391, 1000)\n"]}]},{"cell_type":"code","source":["label_test[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EBCPkMR2RwQb","executionInfo":{"status":"ok","timestamp":1643735682716,"user_tz":-60,"elapsed":216,"user":{"displayName":"Andreea Iuga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05848952328031788406"}},"outputId":"3bd44796-b484-4dc2-9587-877af557b01a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":68}]},{"cell_type":"code","source":["score = loaded_model.evaluate(X_test, y_test, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jMqGcBcsCDJE","executionInfo":{"status":"ok","timestamp":1643732001601,"user_tz":-60,"elapsed":262791,"user":{"displayName":"Andreea Iuga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05848952328031788406"}},"outputId":"b53fb294-64f6-4f94-b3fd-e2ed74670082"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["127/127 [==============================] - 223s 2s/step - loss: 0.6609 - accuracy: 0.6800\n"]}]},{"cell_type":"code","source":["print(\"%s: %.2f%%\" % (loaded_model.metrics_names[0], score[0]*100))\n","print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ctKJCcgxCD8W","executionInfo":{"status":"ok","timestamp":1643732220046,"user_tz":-60,"elapsed":227,"user":{"displayName":"Andreea Iuga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05848952328031788406"}},"outputId":"56357da4-1772-418b-91e6-adcd2afe91b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loss: 66.09%\n","accuracy: 68.00%\n"]}]},{"cell_type":"code","source":["print(X_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"96uE8cfBL7GA","executionInfo":{"status":"ok","timestamp":1643734291516,"user_tz":-60,"elapsed":227,"user":{"displayName":"Andreea Iuga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05848952328031788406"}},"outputId":"a092d0f1-605b-41ff-e1e1-dfa5aaf7739d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(4040, 1000)\n"]}]},{"cell_type":"code","source":["pred = loaded_model.predict(np.expand_dims(X_test[0], 0))\n","pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Er5YXy-OL5h0","executionInfo":{"status":"ok","timestamp":1643734378127,"user_tz":-60,"elapsed":2319,"user":{"displayName":"Andreea Iuga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05848952328031788406"}},"outputId":"389dae47-9b27-4ad1-9cac-f4903daede00"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.22549923, 0.7745008 ]], dtype=float32)"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["np.expand_dims(X_test[0],0).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bp0bEtf1Nas1","executionInfo":{"status":"ok","timestamp":1643734564077,"user_tz":-60,"elapsed":6,"user":{"displayName":"Andreea Iuga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05848952328031788406"}},"outputId":"56044fef-da11-4351-8a4b-59bc91268546"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 1000)"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["X_test[0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7BC7j7KQNzAA","executionInfo":{"status":"ok","timestamp":1643734585438,"user_tz":-60,"elapsed":270,"user":{"displayName":"Andreea Iuga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05848952328031788406"}},"outputId":"101d409e-09c2-4f23-bd99-e3fdff2f520c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1000,)"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["text = np.concatenate((article_train, article_valid, article_test), axis=0)\n","text = np.array(text)\n","\n","tokenizer = Tokenizer(num_words=75000)\n","tokenizer.fit_on_texts(text)\n"],"metadata":{"id":"GaLrXuCdOTj9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = np.array([\"desi nu s-a auzit nicio bubuitura foarte puternica iar fumul din zona este la fel ca de obicei , mai multi bucuresteni sustin ca statia spatiala chinezeasca s-a prabusit in cartierul colentina . acestia isi sustin afirmatiile cu faptul ca peste tot e plin de chinezi si de cratere , exact ca pe luna pe vremuri , ultima oara cand m-am uitat in jur , cartierul asta arata foarte frumos . chiar tin minte cand s-a infiintat prima data spitalul aici , pe vremea lui grigore ghica al doilea\"])\n","sequences = tokenizer.texts_to_sequences(text)\n","sequences = pad_sequences(sequences, maxlen=1000)\n","print(sequences.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YiYaH3uwPKeu","executionInfo":{"status":"ok","timestamp":1643735660225,"user_tz":-60,"elapsed":330,"user":{"displayName":"Andreea Iuga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05848952328031788406"}},"outputId":"9abe3ba9-bf03-4d48-8397-93b986ab9c76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 1000)\n"]}]},{"cell_type":"code","source":["sequences = np.array(sequences)\n","print(sequences.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tMynKjrqPbmv","executionInfo":{"status":"ok","timestamp":1643735326502,"user_tz":-60,"elapsed":221,"user":{"displayName":"Andreea Iuga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05848952328031788406"}},"outputId":"e9f688e8-5a8f-4104-9a12-f4f09f472fae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 5)\n"]}]},{"cell_type":"code","source":["n = len(sequences[0])\n","sequences = np.array(([0] * (1000 - n)).extend(sequences[0]))\n","print(sequences.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XbHFPRiuRNhT","executionInfo":{"status":"ok","timestamp":1643735486698,"user_tz":-60,"elapsed":224,"user":{"displayName":"Andreea Iuga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05848952328031788406"}},"outputId":"9b1f7a08-c480-40c1-8be1-995f81828bf1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["()\n"]}]},{"cell_type":"code","source":["pred = loaded_model.predict(sequences)"],"metadata":{"id":"gy6oQWNlQwFB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"fIU6Gpd-R-dO"},"execution_count":null,"outputs":[]}]}