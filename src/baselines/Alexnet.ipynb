{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Alexnet.ipynb","provenance":[],"collapsed_sections":["2XW_06Ss9HvK","7E93Y9Ur9hP0","mU5GcQ1uO2UD","Pztfwzys-Twj","fynQaA8c-3sB"],"authorship_tag":"ABX9TyP1HDonnIWTr1D24oTdlcMV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Importing the Required Modules"],"metadata":{"id":"2XW_06Ss9HvK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dy6FyVZpx8Gz"},"outputs":[],"source":["# Standard Libraries\n","import re\n","import pickle\n","\n","# Data Libraries\n","import pandas as pd\n","import numpy as np\n","\n","# Functionality\n","from typing import List, Dict, Union"]},{"cell_type":"code","source":["from torch.utils.data.dataset import Dataset\n","from torch.utils.data.dataloader import DataLoader\n","from torchvision import transforms\n","import torchvision.models as models\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch\n","import time\n","import os\n","import copy\n","import argparse"],"metadata":{"id":"oDtDzqvOynHF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from torch.autograd import Variable, Function\n","from sklearn import metrics\n","from tqdm import tqdm"],"metadata":{"id":"c9Fhmr4LvrhZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pathlib import Path\n","PATH=Path(\"drive/MyDrive/ACS_AI_A1/\") "],"metadata":{"id":"E_iidSQTqEUB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PATH_SHARED=Path(\"drive/MyDrive/research/\") \n","!ls $PATH_SHARED"],"metadata":{"id":"LnQIuYq1YKnt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Loading the Dataset"],"metadata":{"id":"7E93Y9Ur9hP0"}},{"cell_type":"code","source":["data_news_all = pd.read_csv(f\"{PATH}/Research/Combined/sarcastic_nonsarcastic_img.csv\")"],"metadata":{"id":"xSdbnx6RD4td"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["images = data_news_all['photo_path'].values\n","label = data_news_all['sarcastic'].values"],"metadata":{"id":"0JgMhZnuvxkt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["images, image_rem, label, label_rem = train_test_split(images, label, train_size=0.17, random_state=42)"],"metadata":{"id":"YVRiWhKSBDjO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_train, image_rem, label_train, label_rem = train_test_split(images, label, train_size=0.8, random_state=42) \n","image_valid, image_test, label_valid, label_test = train_test_split(image_rem, label_rem, test_size=0.6, random_state=42) "],"metadata":{"id":"3nIUHvGqv3RI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Shape of training data: ')\n","print(image_train.shape)\n","print(label_train.shape)\n","\n","print('Shape of val data: ')\n","print(image_valid.shape)\n","print(label_valid.shape)\n","\n","print('Shape of test data: ')\n","print(image_test.shape)\n","print(label_test.shape)"],"metadata":{"id":"s4UT6s1hBXDL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_train = {\n","    \"photo_path\": image_train,\n","    \"image_label\": label_train\n","}\n","dataframe_train = pd.DataFrame(dataset_train)"],"metadata":{"id":"Hkco_x__45Vb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_test = {\n","    \"photo_path\": image_test,\n","    \"image_label\": label_test\n","}\n","dataframe_test = pd.DataFrame(dataset_test)"],"metadata":{"id":"1jHPzLJZ5NZy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_valid = {\n","    \"photo_path\": image_valid,\n","    \"image_label\": label_valid\n","}\n","dataframe_valid = pd.DataFrame(dataset_valid)"],"metadata":{"id":"znV-_LbN5M_S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","class CustomDatasetFromCSV(Dataset):\n","    def __init__(self, csv, transforms=None):\n","        self.data = csv\n","        self.labels = np.asarray(self.data.iloc[:, 1])\n","        self.transforms = transforms\n","\n","    def __getitem__(self, index):\n","        single_image_label = self.labels[index]\n","        single_image_path = self.data.photo_path[index]\n","        \n","        \n","        im_as_im = Image.open(rf\"{single_image_path}\")\n","        \n","        img_as_np = np.asarray(im_as_im)\n","\n","        img_as_img = Image.fromarray(img_as_np.astype(np.uint8))\n","        img_as_img = img_as_img.convert('RGB')\n","        \n","        if self.transforms is not None:\n","            img_as_tensor = self.transforms(img_as_img)\n","        return (img_as_tensor, single_image_label)\n","\n","    def __len__(self):\n","        return len(self.data.index)"],"metadata":{"id":"SHBEZ6Vbqv7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transformations = transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5,), (0.5,))\n","    ])\n"],"metadata":{"id":"CcpUQ3LCr7vN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = \\\n","    CustomDatasetFromCSV(dataframe_train, transformations)\n","loader_train = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                                    batch_size=10,\n","                                                    shuffle=False)\n","test_dataset = \\\n","    CustomDatasetFromCSV(dataframe_test, transformations)\n","loader_test = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                                    batch_size=10,\n","                                                    shuffle=False)\n","valid_dataset = \\\n","    CustomDatasetFromCSV(dataframe_valid, transformations)\n","loader_valid = torch.utils.data.DataLoader(dataset=valid_dataset,\n","                                                    batch_size=10,\n","                                                    shuffle=False)"],"metadata":{"id":"W3Bc_4rb5raB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Detect if we have a GPU available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WcOfIJZLsXM6","executionInfo":{"status":"ok","timestamp":1644788284353,"user_tz":-60,"elapsed":3,"user":{"displayName":"Andreea Iuga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05848952328031788406"}},"outputId":"04fcad93-3d41-4aa5-933b-f9fb9e5e6012"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["# Alexnet\n"],"metadata":{"id":"mU5GcQ1uO2UD"}},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"Pztfwzys-Twj"}},{"cell_type":"code","source":["import torch.nn.functional as F\n","class Alexnet(nn.Module):\n","    def __init__(self):\n","        super(Alexnet, self).__init__()\n","\n","        alexnet = models.alexnet(pretrained=True)\n","        params = []\n","        for param in alexnet.parameters():\n","            param.requires_grad = False\n","\n","            params.append(param)\n","\n","        params[-1].requires_grad = True # retrain last dense layer's bias\n","        params[-2].requires_grad = True # retrain last dense layer's weights    \n","\n","        num_ftrs = alexnet.classifier._modules['6'].out_features\n","        self.vgg = alexnet\n","        self.image_fc1 = nn.Linear(num_ftrs, 64)\n","        self.image_adv = nn.Linear(64, int(64))\n","        self.image_encoder = nn.Linear(64, 64)\n","\n","        self.class_classifier = nn.Sequential()\n","        self.class_classifier.add_module('c_fc1', nn.Linear(64, 2))\n","        self.class_classifier.add_module('c_softmax', nn.Softmax(dim=1))\n","      \n","    def forward(self, image):\n","      image = self.vgg(image) \n","      image = F.relu(self.image_fc1(image))\n","\n","      class_output = self.class_classifier(image)\n","\n","      return class_output"],"metadata":{"id":"idxWf3E1O2UD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" def train_loop(model: Alexnet, train_loader, valid_loader, num_epochs = 10, lr = 0.001, verbose = True):\n","    \n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(\n","        filter(lambda p: p.requires_grad, list(model.parameters())),\n","        lr=lr, \n","        weight_decay=0.1\n","    )\n","\n","    best_valid_acc = 0.0\n","\n","    for epoch in tqdm(range(num_epochs)):\n","\n","        p = float(epoch) / num_epochs\n","\n","        optimizer.lr = 0.001 / (1. + 10 * p) ** 0.75\n","        cost_vector = []\n","        class_cost_vector = []\n","        domain_cost_vector = []\n","        acc_vector = []\n","\n","        for inputs, labels in train_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            \n","            optimizer.zero_grad()\n","            class_outputs = model(inputs)\n","\n","            class_loss = criterion(class_outputs, labels)\n","\n","            loss = class_loss\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            _, argmax = torch.max(class_outputs, 1)\n","            accuracy = (labels == argmax.squeeze()).float().mean()\n","\n","            class_cost_vector.append(class_loss.item())\n","            cost_vector.append(loss.item())\n","            acc_vector.append(accuracy.item())\n","\n","        model.eval()\n","        results = evaluate_loop(model, valid_loader)\n","        model.train()\n","\n","        best = False\n","        if results['label']['accuracy'] > best_valid_acc:\n","            best_valid_acc = results['label']['accuracy']\n","            best = True\n","\n","        if not os.path.exists(f'{PATH}/Research/Alexnet'):\n","            os.makedirs(f'{PATH}/Research/Alexnet')\n","\n","        model_name = str(epoch + 1)\n","        if best:\n","            model_name = model_name + '-best'\n","            best_model_path = os.path.join(f'{PATH}/Research/Alexnet', model_name)\n","\n","        torch.save(model.state_dict(), os.path.join(f'{PATH}/Research/Alexnet', model_name))\n","\n","        if verbose:\n","            print('Epoch [%d/%d],  Loss: %.4f, Class Loss: %.4f, Train_Acc: %.4f,  Validate_Acc: %.4f.' % \\\n","                (\n","                    epoch + 1, \n","                    num_epochs, \n","                    np.mean(cost_vector), \n","                    np.mean(class_cost_vector),\n","                    np.mean(acc_vector), \n","                    results['label']['accuracy']\n","                )\n","            )\n","\n","    return best_model_path"],"metadata":{"id":"pAGBbGXHO2UE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_loop(model, test_dataset):\n","\n","    label_pred = []\n","    label_true = []\n","    for i in range(test_dataset.__len__()):\n","\n","        label_outputs = model(test_dataset.__getitem__(i)[0].view(1, 3, 224, 224))\n","        _, label_argmax = torch.max(label_outputs, 1)\n","\n","        \n","        label_pred.append(label_argmax.squeeze().cpu().numpy())\n","        label_true.append(test_dataset.__getitem__(i)[1])\n","\n","\n","\n","    preds = {\n","        'label': {\n","            'pred': label_pred,\n","            'true': label_true\n","        }\n","    }\n","\n","    results = {name: {} for name in preds}\n","\n","    pred_name = 'label'\n","    pred = preds[pred_name]['pred']\n","    true = preds[pred_name]['true']\n","\n","    results[pred_name]['accuracy'] = metrics.accuracy_score(true, pred)\n","    results[pred_name]['f1_score'] = metrics.f1_score(true, pred, average='macro')\n","    results[pred_name]['precision'] = metrics.precision_score(true, pred, average='macro')\n","    results[pred_name]['recall'] = metrics.recall_score(true, pred, average='macro')\n","    results[pred_name]['confusion_matrix'] = metrics.confusion_matrix(true, pred)\n","    results[pred_name]['report'] = metrics.classification_report(true, pred)\n","\n","    return results"],"metadata":{"id":"79f-3hPnO2UE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Alexnet()\n","model.to(device)"],"metadata":{"id":"LJO3Q_QAO2UD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_path = train_loop(\n","    model=model, \n","    train_loader=loader_train, \n","    valid_loader=valid_dataset,\n","    num_epochs=1\n",")\n","model_path"],"metadata":{"id":"GXIXEZpzO2UE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict(model, test_image_tensor):\n","    with torch.no_grad():\n","        model.eval()\n","        out = model(test_image_tensor)\n","        ps = torch.exp(out)\n","        topk, topclass = ps.topk(1, dim=1)\n","        print(\"Output class :  \", topclass.cpu().numpy()[0][0])\n","    return topclass"],"metadata":{"id":"e8hqyhn0O2UE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results = evaluate_loop(model, test_dataset)\n","results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644693512794,"user_tz":-60,"elapsed":39703,"user":{"displayName":"Andreea Iuga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05848952328031788406"}},"outputId":"a03f9697-ed74-4da7-cf70-f829e2abcaa9","id":"cOugW7npO2UE"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'label': {'accuracy': 0.6929460580912863,\n","  'confusion_matrix': array([[176,  79],\n","         [ 69, 158]]),\n","  'f1_score': 0.6925172413793104,\n","  'precision': 0.6925170068027211,\n","  'recall': 0.6931156603610606,\n","  'report': '              precision    recall  f1-score   support\\n\\n           0       0.72      0.69      0.70       255\\n           1       0.67      0.70      0.68       227\\n\\n    accuracy                           0.69       482\\n   macro avg       0.69      0.69      0.69       482\\nweighted avg       0.69      0.69      0.69       482\\n'}}"]},"metadata":{},"execution_count":124}]},{"cell_type":"markdown","source":["## Saving the model"],"metadata":{"id":"fynQaA8c-3sB"}},{"cell_type":"code","source":["torch.save(model.state_dict(), f\"{PATH}/Research/Alexnet/weights.h5\")"],"metadata":{"id":"tm4A7C01O2UE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(model, f\"{PATH}/Research/Alexnet/model.pth\")"],"metadata":{"id":"FmWAtTafO2UF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_scripted = torch.jit.script(model) \n","model_scripted.save(f\"{PATH}/Research/Alexnet/model.pt\")\n"],"metadata":{"id":"qyHSJVdiO2UF"},"execution_count":null,"outputs":[]}]}